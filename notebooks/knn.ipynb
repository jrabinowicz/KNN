{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis con KNN\n",
    "## Clasificador en C++ ðŸ’ªðŸ’ª\n",
    "Vamos a probar a nuestro bichito\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir los path al ejecutable de python 3.6 y sus librerÃ­as,\n",
    "de acuerdo al virtual env que estÃ©n corriendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory â€˜buildâ€™: File exists\n",
      "-- The C compiler identification is GNU 7.4.0\n",
      "-- The CXX compiler identification is GNU 7.4.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "Release mode\n",
      "-- Found PythonInterp: /mnt/c/users/ami/desktop/Facultad/MÃ©todos/tp2/metnum-tp2-20192c/tp2/bin/python (found version \"3.6.8\") \n",
      "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.6m.so\n",
      "-- pybind11 v2.3.dev0\n",
      "-- Performing Test HAS_FLTO\n",
      "-- Performing Test HAS_FLTO - Success\n",
      "-- LTO enabled\n",
      "CMAKE_INSTALL_PREFIX=/mnt/c/users/ami/desktop/Facultad/MÃ©todos/tp2/metnum-tp2-20192c\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /mnt/c/users/ami/desktop/Facultad/MÃ©todos/tp2/metnum-tp2-20192c/build\n",
      "\u001b[35m\u001b[1mScanning dependencies of target tp2\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/main.cpp.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/knn.cpp.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/pca.cpp.o\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/eigen.cpp.o\u001b[0m\n",
      "[ 50%] \u001b[32m\u001b[1mLinking CXX executable tp2\u001b[0m\n",
      "[ 50%] Built target tp2\n",
      "\u001b[35m\u001b[1mScanning dependencies of target sentiment\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/sentiment.cpp.o\u001b[0m\n",
      "[ 70%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/knn.cpp.o\u001b[0m\n",
      "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/pca.cpp.o\u001b[0m\n",
      "[ 90%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/eigen.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared module sentiment.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
      "[100%] Built target sentiment\n",
      "\u001b[36mInstall the project...\u001b[0m\n",
      "-- Install configuration: \"Release\"\n",
      "-- Installing: /mnt/c/users/ami/desktop/Facultad/MÃ©todos/tp2/metnum-tp2-20192c/notebooks/sentiment.cpython-36m-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "!cd .. && git submodule init\n",
    "!cd .. && git submodule update\n",
    "!cd .. && mkdir build\n",
    "!cd ../build/ && rm -rf *\n",
    "!cd ../build && cmake \\\n",
    "  -DPYTHON_EXECUTABLE=\"$(which python)\" \\\n",
    "  -DCMAKE_BUILD_TYPE=Release ..\n",
    "!cd ../build && make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/users/ami/desktop/Facultad/MÃ©todos/tp2/metnum-tp2-20192c/notebooks\n",
      "Python 3.6.8\n"
     ]
    }
   ],
   "source": [
    "# Verifico la correcta instalaciÃ³n. Si no falla el import estÃ¡ OK\n",
    "!pwd\n",
    "!python --version\n",
    "import sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "tar: *.tgz: Cannot open: No such file or directory\n",
      "tar: Error is not recoverable: exiting now\n",
      "tar: *.tar.gz: Cannot open: No such file or directory\n",
      "tar: Error is not recoverable: exiting now\n",
      "Cantidad de documentos: 12500\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "\n",
    "!cd ../data && tar -xvf *.tgz\n",
    "!cd ../data && tar -xvf *.tar.gz\n",
    "\n",
    "df = pd.read_csv(\"../data/imdb_small.csv\", index_col=0)\n",
    "\n",
    "print(\"Cantidad de documentos: {}\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>12469</td>\n",
       "      <td>2</td>\n",
       "      <td>12085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>test</td>\n",
       "      <td>Seriously, I donÃ‚Â´t really get why people here...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10628_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6275</td>\n",
       "      <td>2</td>\n",
       "      <td>6322</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         type                                             review  label  \\\n",
       "count   12500                                              12500  12500   \n",
       "unique      2                                              12469      2   \n",
       "top      test  Seriously, I donÃ‚Â´t really get why people here...    neg   \n",
       "freq     6275                                                  2   6322   \n",
       "\n",
       "               file  \n",
       "count         12500  \n",
       "unique        12085  \n",
       "top     10628_1.txt  \n",
       "freq              2  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de instancias de entrenamiento = 1000\n",
      "Cantidad de instancias de test = 500\n"
     ]
    }
   ],
   "source": [
    "text_train = (df[df.type == 'train'][\"review\"])[:1000]\n",
    "label_train = (df[df.type == 'train'][\"label\"])[:1000]\n",
    "\n",
    "text_test = (df[df.type == 'test'][\"review\"])[:500]\n",
    "label_test = (df[df.type == 'test'][\"label\"])[:500]\n",
    "\n",
    "print(\"Cantidad de instancias de entrenamiento = {}\".format(len(text_train)))\n",
    "print(\"Cantidad de instancias de test = {}\".format(len(text_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance : 0.512 pos 0.488 neg\n"
     ]
    }
   ],
   "source": [
    "print(\"Class balance : {} pos {} neg\".format(\n",
    "    (label_train == 'pos').sum() / label_train.shape[0], \n",
    "    (label_train == 'neg').sum() / label_train.shape[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.90, min_df=0.01, max_features=5000)\n",
    "\n",
    "vectorizer.fit(text_train)\n",
    "\n",
    "X_train, y_train = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "X_test, y_test = vectorizer.transform(text_test), (label_test == 'pos').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentiment\n",
    "\n",
    "clf = sentiment.KNNClassifier(100)\n",
    "\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.572\n",
      "CPU times: user 7.73 s, sys: 14.3 s, total: 22.1 s\n",
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sentiment\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "df = pd.read_csv(\"../data/imdb_small.csv\", index_col=0)\n",
    "\n",
    "#codigo de countvectorizer\n",
    "vectorizer = CountVectorizer(max_df=0.90, min_df=0.01, max_features=5000)\n",
    "\n",
    "vectorizer.fit(text_train)\n",
    "\n",
    "X_train, y_train = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "X_test, y_test = vectorizer.transform(text_test), (label_test == 'pos').values\n",
    "\n",
    "#randomizar la base\n",
    "df = df.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de instancias de entrenamiento = 9375\n",
      "Cantidad de instancias de test = 3125\n",
      "Alpha 140\n",
      "Entrenando PCA\n"
     ]
    }
   ],
   "source": [
    "#TEST UMBRALES BOLSA DE PALABRAS\n",
    "\n",
    "#Usamos los k y alpha que optimizaban knn y pca\n",
    "k = 130\n",
    "alpha = 140\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "df = pd.read_csv(\"../data/imdb_small.csv\", index_col=0)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentiment import PCA, KNNClassifier, get_first_eigenvalues\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "borde = 9375\n",
    "text_train = df[:borde][\"review\"]\n",
    "label_train = df[:borde][\"label\"]\n",
    "\n",
    "text_test = df[borde:][\"review\"]\n",
    "label_test = df[borde:][\"label\"]\n",
    "\n",
    "print(\"Cantidad de instancias de entrenamiento = {}\".format(len(text_train)))\n",
    "print(\"Cantidad de instancias de test = {}\".format(len(text_test)))\n",
    "\n",
    "\n",
    "min_max = []\n",
    "\n",
    "for i in range (0,11):\n",
    "    vectorizer = CountVectorizer(max_df=1.0-i*0.05, min_df=0.0+i*0.005, max_features=5000)\n",
    "    vectorizer.fit(text_train)\n",
    "    X_train, y_train = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "    X_test, y_test = vectorizer.transform(text_test), (label_test == 'pos').values\n",
    "    pruebas = []\n",
    "    \n",
    "    pca = PCA(alpha)\n",
    "    print(\"Alpha {}\".format(alpha))\n",
    "    print(\"Entrenando PCA\")\n",
    "\n",
    "    #print(type(X_train))\n",
    "    pca.fit(X_train.toarray())\n",
    "    #print(type(X_train))\n",
    "    X_pca_train = pca.transform(X_train)\n",
    "    #print(type(X_train))\n",
    "    X_pca_test = pca.transform(X_test)\n",
    "    acc = []\n",
    "    \n",
    "        ## Creo y entreno\n",
    "    clf = KNNClassifier(k)\n",
    "    clf.fit(X_pca_train, y_train)\n",
    "\n",
    "    # Predigo\n",
    "    y_pred = clf.predict(X_pca_test)\n",
    "\n",
    "    # Me fijo el accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc.append(accuracy)\n",
    "    print(acc)\n",
    "    #print(\"k = {} alpha = {} ----> {}\".format(k, alpha, accuracy))\n",
    "\n",
    "    min_max.append((0.0+i*0.005,1.0-i*0.05))\n",
    "    pruebas.append({\n",
    "        \"max_df\": 1.0-i*0.05,\n",
    "        \"min_df\": 0.0+i*0.005,\n",
    "        \"acc\": acc,\n",
    "    })\n",
    "    plt.plot(min_max, acc, '-o')\n",
    "    print(acc)\n",
    "        \n",
    "\n",
    "plt.legend(Umbrales, loc='upper left')\n",
    "plt.xlabel(\"Umbrales\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(min_max)\n",
    "plt.title(\"Performance de clasificador en funciÃ³n a umbrales de la bolsa de palabras\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de instancias de entrenamiento = 9375\n",
      "Cantidad de instancias de test = 3125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-44ca20e45334>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mpruebas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/UBA/metnum/tp2/metnum-tp2-20192c/tp2/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/UBA/metnum/tp2/metnum-tp2-20192c/tp2/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfeature_idx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_counter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m                         \u001b[0mfeature_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TEST DE CAMBIO DE N_NEIGHBORS Y ALPHA \n",
    "# (es decir, el de Rodri)\n",
    "\n",
    "#SACAR ESTOS IMPORTS Y HACER Q ANDEN CON LOS DE ARRIBA\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "df = pd.read_csv(\"../data/imdb_small.csv\", index_col=0)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentiment import PCA, KNNClassifier, get_first_eigenvalues\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CAMBIAR 6225 POR 3125 (AMI) Y 9375 (JULI)\n",
    "borde = 9375\n",
    "text_train = df[:borde][\"review\"]\n",
    "label_train = df[:borde][\"label\"]\n",
    "\n",
    "text_test = df[borde:][\"review\"]\n",
    "label_test = df[borde:][\"label\"]\n",
    "\n",
    "print(\"Cantidad de instancias de entrenamiento = {}\".format(len(text_train)))\n",
    "print(\"Cantidad de instancias de test = {}\".format(len(text_test)))\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.90, min_df=0.01, max_features=5000)\n",
    "vectorizer.fit(text_train)\n",
    "X_train, y_train = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "X_test, y_test = vectorizer.transform(text_test), (label_test == 'pos').values\n",
    "pruebas = []\n",
    "\n",
    "\n",
    "alphas = list(range(50, 101, 5))\n",
    "\n",
    "for alpha in alphas:\n",
    "    pca = PCA(alpha)\n",
    "    print(\"Alpha {}\".format(alpha))\n",
    "    print(\"Entrenando PCA\")\n",
    "\n",
    "    #print(type(X_train))\n",
    "    pca.fit(X_train.toarray())\n",
    "    #print(type(X_train))\n",
    "    X_pca_train = pca.transform(X_train)\n",
    "    #print(type(X_train))\n",
    "    X_pca_test = pca.transform(X_test)\n",
    "    acc = []\n",
    "    for k in range(100,151,3):\n",
    "        ## Creo y entreno\n",
    "        clf = KNNClassifier(k)\n",
    "        clf.fit(X_pca_train, y_train)\n",
    "\n",
    "        # Predigo\n",
    "        y_pred = clf.predict(X_pca_test)\n",
    "\n",
    "        # Me fijo el accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        acc.append(accuracy)\n",
    "        print(acc)\n",
    "        #print(\"k = {} alpha = {} ----> {}\".format(k, alpha, accuracy))\n",
    "        \n",
    "        pruebas.append({\n",
    "            \"k\": k,\n",
    "            \"alpha\": alpha,\n",
    "            \"acc\": acc,\n",
    "        })\n",
    "    plt.plot(list(range(100,151,3)), acc, '-o')\n",
    "    print(acc)\n",
    "        \n",
    "\n",
    "plt.legend(alphas, loc='upper left')\n",
    "plt.xlabel(\"Vecinos\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(list(range(100,151,3)))\n",
    "plt.title(\"Performance de clasificador en funciÃ³n a cantidad de vecinos y alpha\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando n=9375\n",
      "Cantidad de instancias de entrenamiento = 9375\n",
      "Cantidad de instancias de test = 3124\n",
      "Vectorizando...\n"
     ]
    }
   ],
   "source": [
    "# TEST DE TAMAÃ‘O DE INSTANCIAS DE ENTRENAMIENTO vs TEST CON KNN VARIABLE\n",
    "import sentiment\n",
    "res1 = []\n",
    "division = list(range(9375,12500,3125)) #1/4, 1/2, 3/4 de la base se usan para train\n",
    "rangos = [(x,12500-x) for x in division]\n",
    "#Orig: 501\n",
    "knns = list(range(80,151,5))\n",
    "\n",
    "for n in division:\n",
    "    print(\"Analizando n={}\".format(n))\n",
    "    acc = []\n",
    "    \n",
    "    #Divido train y test\n",
    "    text_train = df[:n][\"review\"]\n",
    "    label_train = df[:n][\"label\"]\n",
    "    text_test = df[n+1:][\"review\"]\n",
    "    label_test = df[n+1:][\"label\"]\n",
    "    print(\"Cantidad de instancias de entrenamiento = {}\".format(len(text_train)))\n",
    "    print(\"Cantidad de instancias de test = {}\".format(len(text_test)))\n",
    "    #Hago BoW\n",
    "    print(\"Vectorizando...\")\n",
    "    vectorizer = CountVectorizer(max_df=0.90, min_df=0.01, max_features=5000)\n",
    "    vectorizer.fit(text_train)\n",
    "    X_train, y_train = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "    X_test, y_test = vectorizer.transform(text_test), (label_test == 'pos').values\n",
    "    \n",
    "    #Aplico KNN\n",
    "    for k in knns:\n",
    "        print(\"Para {} vecinos\".format(k))        \n",
    "        clf = sentiment.KNNClassifier(k)\n",
    "        print(\"Hago fit...\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        #Predigo\n",
    "        print(\"Predigo...\")\n",
    "        y_pred = clf.predict(X_test)\n",
    "        #Calculo accuracy y guardo resultado\n",
    "        acc.append(accuracy_score(y_test, y_pred))\n",
    "        print(\"Accuracy: {}\".format(acc))\n",
    "    plt.plot(knns, acc, '-o')\n",
    "\n",
    "plt.legend(rangos, loc='upper left')\n",
    "plt.xlabel(\"Vecinos\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(knns)\n",
    "plt.title(\"Performance de clasificador en funciÃ³n de tamaÃ±o de la base de entrenamiento\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
