{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis con KNN\n",
    "## Clasificador en C++ ðŸ’ªðŸ’ª\n",
    "Vamos a probar a nuestro bichito\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir los path al ejecutable de python 3.6 y sus librerÃ­as,\n",
    "de acuerdo al virtual env que estÃ©n corriendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory â€˜buildâ€™: File exists\n",
      "-- The C compiler identification is GNU 7.4.0\n",
      "-- The CXX compiler identification is GNU 7.4.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "Release mode\n",
      "-- Found PythonInterp: /mnt/c/users/ami/desktop/Facultad/MÃ©todos/tp2/metnum-tp2-20192c/tp2/bin/python (found version \"3.6.8\") \n",
      "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.6m.so\n",
      "-- pybind11 v2.3.dev0\n",
      "-- Performing Test HAS_FLTO\n",
      "-- Performing Test HAS_FLTO - Success\n",
      "-- LTO enabled\n",
      "CMAKE_INSTALL_PREFIX=/mnt/c/users/ami/desktop/Facultad/MÃ©todos/tp2/metnum-tp2-20192c\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /mnt/c/users/ami/desktop/Facultad/MÃ©todos/tp2/metnum-tp2-20192c/build\n",
      "\u001b[35m\u001b[1mScanning dependencies of target tp2\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/main.cpp.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/knn.cpp.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/pca.cpp.o\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/eigen.cpp.o\u001b[0m\n",
      "[ 50%] \u001b[32m\u001b[1mLinking CXX executable tp2\u001b[0m\n",
      "[ 50%] Built target tp2\n",
      "\u001b[35m\u001b[1mScanning dependencies of target sentiment\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/sentiment.cpp.o\u001b[0m\n",
      "[ 70%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/knn.cpp.o\u001b[0m\n",
      "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/pca.cpp.o\u001b[0m\n",
      "[ 90%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/eigen.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared module sentiment.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
      "[100%] Built target sentiment\n",
      "\u001b[36mInstall the project...\u001b[0m\n",
      "-- Install configuration: \"Release\"\n",
      "-- Installing: /mnt/c/users/ami/desktop/Facultad/MÃ©todos/tp2/metnum-tp2-20192c/notebooks/sentiment.cpython-36m-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "!cd .. && git submodule init\n",
    "!cd .. && git submodule update\n",
    "!cd .. && mkdir build\n",
    "!cd ../build/ && rm -rf *\n",
    "!cd ../build && cmake \\\n",
    "  -DPYTHON_EXECUTABLE=\"$(which python)\" \\\n",
    "  -DCMAKE_BUILD_TYPE=Release ..\n",
    "!cd ../build && make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/users/ami/desktop/Facultad/MÃ©todos/tp2/metnum-tp2-20192c/notebooks\n",
      "Python 3.6.8\n"
     ]
    }
   ],
   "source": [
    "# Verifico la correcta instalaciÃ³n. Si no falla el import estÃ¡ OK\n",
    "!pwd\n",
    "!python --version\n",
    "import sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "tar: *.tgz: Cannot open: No such file or directory\n",
      "tar: Error is not recoverable: exiting now\n",
      "tar: *.tar.gz: Cannot open: No such file or directory\n",
      "tar: Error is not recoverable: exiting now\n",
      "Cantidad de documentos: 12500\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "\n",
    "!cd ../data && tar -xvf *.tgz\n",
    "!cd ../data && tar -xvf *.tar.gz\n",
    "\n",
    "df = pd.read_csv(\"../data/imdb_small.csv\", index_col=0)\n",
    "\n",
    "print(\"Cantidad de documentos: {}\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>12469</td>\n",
       "      <td>2</td>\n",
       "      <td>12085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>test</td>\n",
       "      <td>Seriously, I donÃ‚Â´t really get why people here...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10628_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6275</td>\n",
       "      <td>2</td>\n",
       "      <td>6322</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         type                                             review  label  \\\n",
       "count   12500                                              12500  12500   \n",
       "unique      2                                              12469      2   \n",
       "top      test  Seriously, I donÃ‚Â´t really get why people here...    neg   \n",
       "freq     6275                                                  2   6322   \n",
       "\n",
       "               file  \n",
       "count         12500  \n",
       "unique        12085  \n",
       "top     10628_1.txt  \n",
       "freq              2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de instancias de entrenamiento = 1000\n",
      "Cantidad de instancias de test = 500\n"
     ]
    }
   ],
   "source": [
    "text_train = (df[df.type == 'train'][\"review\"])[:1000]\n",
    "label_train = (df[df.type == 'train'][\"label\"])[:1000]\n",
    "\n",
    "text_test = (df[df.type == 'test'][\"review\"])[:500]\n",
    "label_test = (df[df.type == 'test'][\"label\"])[:500]\n",
    "\n",
    "print(\"Cantidad de instancias de entrenamiento = {}\".format(len(text_train)))\n",
    "print(\"Cantidad de instancias de test = {}\".format(len(text_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance : 0.512 pos 0.488 neg\n"
     ]
    }
   ],
   "source": [
    "print(\"Class balance : {} pos {} neg\".format(\n",
    "    (label_train == 'pos').sum() / label_train.shape[0], \n",
    "    (label_train == 'neg').sum() / label_train.shape[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.90, min_df=0.01, max_features=5000)\n",
    "\n",
    "vectorizer.fit(text_train)\n",
    "\n",
    "X_train, y_train = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "X_test, y_test = vectorizer.transform(text_test), (label_test == 'pos').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentiment\n",
    "\n",
    "clf = sentiment.KNNClassifier(100)\n",
    "\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.572\n",
      "CPU times: user 14.2 s, sys: 29.4 s, total: 43.6 s\n",
      "Wall time: 47.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        type                                             review label  \\\n",
      "id                                                                      \n",
      "19631   test  This movie is my families favorite Christmas m...   pos   \n",
      "32878  train  Spoiler below, but read on or you'll never kno...   neg   \n",
      "28509  train  One of the worst romantic comedies (nay, worst...   neg   \n",
      "32451  train  An actor asks, \"What's my motivation?,\" to und...   neg   \n",
      "45002  train  Whether this movie is propaganda or not (I fir...   pos   \n",
      "39719  train  I have seen this wonderful production, and I w...   pos   \n",
      "38179  train  What another reviewer called lack of character...   pos   \n",
      "38422  train  I enjoyed Still Crazy more than any film I hav...   pos   \n",
      "21771   test  What impressed me the most about \"One True Thi...   pos   \n",
      "9928    test  This film is unbelievable on any level. It fai...   neg   \n",
      "\n",
      "               file  \n",
      "id                   \n",
      "19631   5169_10.txt  \n",
      "32878    5841_1.txt  \n",
      "28509    1909_1.txt  \n",
      "32451    5457_1.txt  \n",
      "45002   5502_10.txt  \n",
      "39719  11999_10.txt  \n",
      "38179   10611_8.txt  \n",
      "38422  10830_10.txt  \n",
      "21771    7095_7.txt  \n",
      "9928     7687_1.txt  \n",
      "50000\n",
      "        type                                             review label  \\\n",
      "id                                                                      \n",
      "454     test  This is a slick little movie well worth your t...   neg   \n",
      "24408   test  I thought this movie was absolutely hilarious....   pos   \n",
      "7937    test  Am I the only one who thought the point of thi...   neg   \n",
      "20895   test  I've seen this film so many times, It's that g...   pos   \n",
      "49877  train  I first rented this film many years ago, and w...   pos   \n",
      "32747  train  Anyone who has said that it's better than Host...   neg   \n",
      "16511   test  Black Day Blue Night was actually good modern ...   pos   \n",
      "24807   test  Of all the actresses in film today, Kristin Sc...   pos   \n",
      "4206    test  Sherlock Holmes and the Secret Weapon starts i...   neg   \n",
      "45719  train  IN LOVING MEMORY OF DAVID TOMLINSON (1917-2000...   pos   \n",
      "\n",
      "              file  \n",
      "id                  \n",
      "454    10409_2.txt  \n",
      "24408  9469_10.txt  \n",
      "7937    5895_3.txt  \n",
      "20895  6306_10.txt  \n",
      "49877  9891_10.txt  \n",
      "32747   5723_1.txt  \n",
      "16511   2360_7.txt  \n",
      "24807   9828_7.txt  \n",
      "4206    2536_4.txt  \n",
      "45719  6148_10.txt  \n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sentiment\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "df = pd.read_csv(\"../data/imdb_small.csv\", index_col=0)\n",
    "\n",
    "#codigo de countvectorizer\n",
    "#randomizar la base\n",
    "df = df.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de instancias de entrenamiento = 6225\n",
      "Cantidad de instancias de test = 6275\n"
     ]
    }
   ],
   "source": [
    "# TEST DE CAMBIO DE N_NEIGHBORS (SOLO KNN)\n",
    "# ======== OBSOLETO =========\n",
    "#Temporal cambiar 100 a 6225 y sacar limite superior test\n",
    "text_train = df[:6225][\"review\"]\n",
    "label_train = df[:6225][\"label\"]\n",
    "\n",
    "text_test = df[6225:][\"review\"]\n",
    "label_test = df[6225:][\"label\"]\n",
    "\n",
    "print(\"Cantidad de instancias de entrenamiento = {}\".format(len(text_train)))\n",
    "print(\"Cantidad de instancias de test = {}\".format(len(text_test)))\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.90, min_df=0.01, max_features=5000)\n",
    "vectorizer.fit(text_train)\n",
    "X_train, y_train = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "X_test, y_test = vectorizer.transform(text_test), (label_test == 'pos').values\n",
    "\n",
    "acc = []\n",
    "neighs = list(range(25,201,25))\n",
    "for n in neighs:\n",
    "    clf = sentiment.KNNClassifier(n)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc.append(accuracy_score(y_test, y_pred))\n",
    "    print(\"Accuracy {}: {}\".format(n,acc))\n",
    "    \n",
    "plt.plot(neighs, acc, 'g-o')\n",
    "plt.xlabel(\"Vecinos\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(neighs)\n",
    "plt.title(\"Performance de clasificador en funciÃ³n a cantidad de vecinos\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de instancias de entrenamiento = 9375\n",
      "Cantidad de instancias de test = 3125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-44ca20e45334>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mpruebas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/UBA/metnum/tp2/metnum-tp2-20192c/tp2/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/UBA/metnum/tp2/metnum-tp2-20192c/tp2/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfeature_idx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_counter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m                         \u001b[0mfeature_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TEST DE CAMBIO DE N_NEIGHBORS Y ALPHA \n",
    "# (es decir, el de Rodri)\n",
    "\n",
    "#SACAR ESTOS IMPORTS Y HACER Q ANDEN CON LOS DE ARRIBA\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "df = pd.read_csv(\"../data/imdb_small.csv\", index_col=0)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentiment import PCA, KNNClassifier, get_first_eigenvalues\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CAMBIAR 6225 POR 3125 (AMI) Y 9375 (JULI)\n",
    "borde = 9375\n",
    "text_train = df[:borde][\"review\"]\n",
    "label_train = df[:borde][\"label\"]\n",
    "\n",
    "text_test = df[borde:][\"review\"]\n",
    "label_test = df[borde:][\"label\"]\n",
    "\n",
    "print(\"Cantidad de instancias de entrenamiento = {}\".format(len(text_train)))\n",
    "print(\"Cantidad de instancias de test = {}\".format(len(text_test)))\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.90, min_df=0.01, max_features=5000)\n",
    "vectorizer.fit(text_train)\n",
    "X_train, y_train = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "X_test, y_test = vectorizer.transform(text_test), (label_test == 'pos').values\n",
    "pruebas = []\n",
    "\n",
    "\n",
    "alphas = list(range(50, 101, 5))\n",
    "\n",
    "for alpha in alphas:\n",
    "    pca = PCA(alpha)\n",
    "    print(\"Alpha {}\".format(alpha))\n",
    "    print(\"Entrenando PCA\")\n",
    "\n",
    "    #print(type(X_train))\n",
    "    pca.fit(X_train.toarray())\n",
    "    #print(type(X_train))\n",
    "    X_pca_train = pca.transform(X_train)\n",
    "    #print(type(X_train))\n",
    "    X_pca_test = pca.transform(X_test)\n",
    "    acc = []\n",
    "    for k in range(100,151,3):\n",
    "        ## Creo y entreno\n",
    "        clf = KNNClassifier(k)\n",
    "        clf.fit(X_pca_train, y_train)\n",
    "\n",
    "        # Predigo\n",
    "        y_pred = clf.predict(X_pca_test)\n",
    "\n",
    "        # Me fijo el accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        acc.append(accuracy)\n",
    "        print(acc)\n",
    "        #print(\"k = {} alpha = {} ----> {}\".format(k, alpha, accuracy))\n",
    "        \n",
    "        pruebas.append({\n",
    "            \"k\": k,\n",
    "            \"alpha\": alpha,\n",
    "            \"acc\": acc,\n",
    "        })\n",
    "    plt.plot(list(range(100,151,3)), acc, '-o')\n",
    "    print(acc)\n",
    "        \n",
    "\n",
    "plt.legend(alphas, loc='upper left')\n",
    "plt.xlabel(\"Vecinos\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(list(range(100,151,3)))\n",
    "plt.title(\"Performance de clasificador en funciÃ³n a cantidad de vecinos y alpha\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando n=9375\n",
      "Cantidad de instancias de entrenamiento = 9375\n",
      "Cantidad de instancias de test = 3124\n",
      "Vectorizando...\n"
     ]
    }
   ],
   "source": [
    "# TEST DE TAMAÃ‘O DE INSTANCIAS DE ENTRENAMIENTO vs TEST CON KNN VARIABLE\n",
    "import sentiment\n",
    "res1 = []\n",
    "division = list(range(9375,12500,3125)) #1/4, 1/2, 3/4 de la base se usan para train\n",
    "rangos = [(x,12500-x) for x in division]\n",
    "#Orig: 501\n",
    "knns = list(range(80,151,5))\n",
    "\n",
    "for n in division:\n",
    "    print(\"Analizando n={}\".format(n))\n",
    "    acc = []\n",
    "    \n",
    "    #Divido train y test\n",
    "    text_train = df[:n][\"review\"]\n",
    "    label_train = df[:n][\"label\"]\n",
    "    text_test = df[n+1:][\"review\"]\n",
    "    label_test = df[n+1:][\"label\"]\n",
    "    print(\"Cantidad de instancias de entrenamiento = {}\".format(len(text_train)))\n",
    "    print(\"Cantidad de instancias de test = {}\".format(len(text_test)))\n",
    "    #Hago BoW\n",
    "    print(\"Vectorizando...\")\n",
    "    vectorizer = CountVectorizer(max_df=0.90, min_df=0.01, max_features=5000)\n",
    "    vectorizer.fit(text_train)\n",
    "    X_train, y_train = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "    X_test, y_test = vectorizer.transform(text_test), (label_test == 'pos').values\n",
    "    \n",
    "    #Aplico KNN\n",
    "    for k in knns:\n",
    "        print(\"Para {} vecinos\".format(k))        \n",
    "        clf = sentiment.KNNClassifier(k)\n",
    "        print(\"Hago fit...\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        #Predigo\n",
    "        print(\"Predigo...\")\n",
    "        y_pred = clf.predict(X_test)\n",
    "        #Calculo accuracy y guardo resultado\n",
    "        acc.append(accuracy_score(y_test, y_pred))\n",
    "        print(\"Accuracy: {}\".format(acc))\n",
    "    plt.plot(knns, acc, '-o')\n",
    "\n",
    "plt.legend(rangos, loc='upper left')\n",
    "plt.xlabel(\"Vecinos\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(knns)\n",
    "plt.title(\"Performance de clasificador en funciÃ³n de tamaÃ±o de la base de entrenamiento\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_df=0.90, min_df=0.01, max_features=5000)\n",
    "\n",
    "vectorizer.fit(text_train)\n",
    "\n",
    "X_train, y_train = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "X_test, y_test = vectorizer.transform(text_test), (label_test == 'pos').values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
